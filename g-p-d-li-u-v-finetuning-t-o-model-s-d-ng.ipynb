{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:12:47.005145Z",
     "iopub.status.busy": "2025-09-09T08:12:47.004885Z",
     "iopub.status.idle": "2025-09-09T08:12:47.040810Z",
     "shell.execute_reply": "2025-09-09T08:12:47.040267Z",
     "shell.execute_reply.started": "2025-09-09T08:12:47.005117Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Tôi là chủ nhiệm một đề tài cấp Bộ, vậy mức thù lao tối đa một tháng của tôi được nhận là bao nhiêu?', 'answer': 'Theo Điều 4, khoản 2 của Quy định, mức thù lao tối đa cho chủ nhiệm nhiệm vụ khoa học và công nghệ cấp Bộ là không quá 30.000.000 đồng/người/tháng.'}\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "with open('/kaggle/input/data-json/question.json', 'r', encoding='utf-8') as f1:\n",
    "    data1_raw = json.load(f1)\n",
    "\n",
    "data1 = []\n",
    "for item in data1_raw:\n",
    "    for qa in item['data']:\n",
    "        data1.append({\n",
    "            'question':qa['question'],\n",
    "            'answer': qa['answer']\n",
    "        })\n",
    "\n",
    "print(data1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:12:47.041552Z",
     "iopub.status.busy": "2025-09-09T08:12:47.041375Z",
     "iopub.status.idle": "2025-09-09T08:12:47.051966Z",
     "shell.execute_reply": "2025-09-09T08:12:47.051319Z",
     "shell.execute_reply.started": "2025-09-09T08:12:47.041535Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Một nhiệm vụ khoa học và công nghệ cấp Bộ được phê duyệt vào ngày 01/05/2025, với tổng dự toán kinh phí chi thù lao là 1 tỷ đồng. Đến ngày 15/06/2025, đơn vị chủ trì muốn thuê một chuyên gia ngoài nước. Mức dự toán kinh phí tối đa cho việc thuê chuyên gia này là bao nhiêu?', 'answer': 'Tình huống: Nhiệm vụ KHCN cấp Bộ đã được phê duyệt trước ngày Quyết định 1892 có hiệu lực (04/06/2025) nhưng vẫn trong thời gian thực hiện và cần thuê chuyên gia ngoài nước sau ngày quyết định có hiệu lực.\\nĐiều luật áp dụng: Điều 6 Quyết định 1892 quy định các nhiệm vụ đã phê duyệt trước ngày Quyết định có hiệu lực thì tiếp tục áp dụng theo quy định tại thời điểm phê duyệt. Tuy nhiên, vì việc thuê chuyên gia ngoài nước xảy ra sau ngày quyết định có hiệu lực nên vẫn phải tuân thủ điều 4 khoản 5c Quyết định 1892 về hạn mức. \\nĐiều 4 khoản 5c Quyết định 1892 quy định tổng dự toán kinh phí chi thuê chuyên gia ngoài nước không quá 50% tổng dự toán kinh phí chi tiền thù lao thực hiện nhiệm vụ khoa học và công nghệ cấp Bộ.\\nKết luận: Mức dự toán kinh phí tối đa cho việc thuê chuyên gia ngoài nước trong trường hợp này là 500 triệu đồng (50% của 1 tỷ đồng).'}\n"
     ]
    }
   ],
   "source": [
    "with open('/kaggle/input/data-json/QA_output_multihop_allQuyetdinh.json', 'r', encoding='utf-8') as f2:\n",
    "    data2_raw = json.load(f2)\n",
    "\n",
    "data2 = []\n",
    "data2 = [{'question': item['question'], 'answer': item['answer']} for item in data2_raw]\n",
    "print(data2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:12:47.052795Z",
     "iopub.status.busy": "2025-09-09T08:12:47.052617Z",
     "iopub.status.idle": "2025-09-09T08:12:47.071064Z",
     "shell.execute_reply": "2025-09-09T08:12:47.070398Z",
     "shell.execute_reply.started": "2025-09-09T08:12:47.052780Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Một tổ chức sự nghiệp công lập trực thuộc Bộ Nông nghiệp và Môi trường, chuyên nghiên cứu về giống cây trồng mới, muốn đề xuất một nhiệm vụ KHCN cấp bộ để cải tạo một giống lúa địa phương. Tuy nhiên, tổ chức này đang chậm nộp báo cáo kết quả ứng dụng của một đề tài KHCN cấp bộ đã nghiệm thu trước đó 7 tháng. Tổ chức này có đủ điều kiện để đề xuất nhiệm vụ KHCN cấp bộ mới không, và nếu không thì quy định nào sẽ được áp dụng?', 'answer': 'Tổ chức này không đủ điều kiện đề xuất nhiệm vụ KHCN cấp bộ mới. Theo Điều 8 Thông tư 2025/TT-BNNMT, tổ chức, cá nhân đề xuất đặt hàng nhiệm vụ KHCN thông qua hệ thống quản lý KHCN của Bộ. Tuy nhiên, theo điểm a khoản 2 Điều 10 Thông tư này, tổ chức chưa hoàn thành việc báo cáo ứng dụng kết quả nhiệm vụ KHCN sử dụng ngân sách nhà nước sẽ không đủ điều kiện đăng ký tham gia tuyển chọn, giao trực tiếp chủ trì nhiệm vụ. Vì tổ chức này chậm nộp báo cáo ứng dụng kết quả nhiệm vụ KHCN đã nghiệm thu trước đó, nên không đủ điều kiện để đề xuất nhiệm vụ KHCN cấp bộ mới.'}\n"
     ]
    }
   ],
   "source": [
    "with open('/kaggle/input/data-json/QA_output_multihop_allThongtu.json', 'r', encoding='utf-8') as f3:\n",
    "    data3_raw = json.load(f3)\n",
    "\n",
    "data3 = []\n",
    "data3 = [{'question': item['question'], 'answer': item['answer']} for item in data3_raw]\n",
    "print(data3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:12:47.072147Z",
     "iopub.status.busy": "2025-09-09T08:12:47.071894Z",
     "iopub.status.idle": "2025-09-09T08:12:47.095349Z",
     "shell.execute_reply": "2025-09-09T08:12:47.094662Z",
     "shell.execute_reply.started": "2025-09-09T08:12:47.072121Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Tôi là chủ nhiệm một đề tài cấp Bộ, vậy mức thù lao tối đa một tháng của tôi được nhận là bao nhiêu?', 'answer': 'Theo Điều 4, khoản 2 của Quy định, mức thù lao tối đa cho chủ nhiệm nhiệm vụ khoa học và công nghệ cấp Bộ là không quá 30.000.000 đồng/người/tháng.'}\n"
     ]
    }
   ],
   "source": [
    "with open(\"/kaggle/input/datasetqamultichoicetf/merged_questions.json\", 'r', encoding='utf-8') as f4:\n",
    "    data_raw4 = json.load(f4)\n",
    "\n",
    "data4 = []\n",
    "for item in data_raw4:\n",
    "    data4.append({\n",
    "        \"question\": item[\"question\"],\n",
    "        \"answer\": item[\"answer\"]\n",
    "    })\n",
    "print(data4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:12:47.096388Z",
     "iopub.status.busy": "2025-09-09T08:12:47.096138Z",
     "iopub.status.idle": "2025-09-09T08:12:47.100980Z",
     "shell.execute_reply": "2025-09-09T08:12:47.099989Z",
     "shell.execute_reply.started": "2025-09-09T08:12:47.096363Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444\n"
     ]
    }
   ],
   "source": [
    "merge_data = data1 + data2 + data3 + data4\n",
    "print(len(merge_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:12:47.104463Z",
     "iopub.status.busy": "2025-09-09T08:12:47.104246Z",
     "iopub.status.idle": "2025-09-09T08:12:47.127080Z",
     "shell.execute_reply": "2025-09-09T08:12:47.126322Z",
     "shell.execute_reply.started": "2025-09-09T08:12:47.104445Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gộp xong. Tổng số QA: 444\n"
     ]
    }
   ],
   "source": [
    "with open('merged_questions.json', 'w', encoding='utf-8') as fout:\n",
    "    json.dump(merge_data, fout, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Gộp xong. Tổng số QA: {len(merge_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:12:47.127945Z",
     "iopub.status.busy": "2025-09-09T08:12:47.127757Z",
     "iopub.status.idle": "2025-09-09T08:12:47.149301Z",
     "shell.execute_reply": "2025-09-09T08:12:47.148660Z",
     "shell.execute_reply.started": "2025-09-09T08:12:47.127927Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Đã chuẩn bị xong 444 mẫu dữ liệu.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load dữ liệu đã merge\n",
    "with open(\"/kaggle/working/merged_questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Format lại thành dạng chat\n",
    "formatted = []\n",
    "for item in data:\n",
    "    chat_item = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": item[\"question\"]},\n",
    "            {\"role\": \"assistant\", \"content\": item[\"answer\"]}\n",
    "        ]\n",
    "    }\n",
    "    formatted.append(chat_item)\n",
    "\n",
    "# Lưu ra file JSONL cho fine-tuning\n",
    "with open(\"finetune_data.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in formatted:\n",
    "        f.write(json.dumps(line, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Đã chuẩn bị xong {len(formatted)} mẫu dữ liệu.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:12:47.150352Z",
     "iopub.status.busy": "2025-09-09T08:12:47.150083Z",
     "iopub.status.idle": "2025-09-09T08:14:04.213068Z",
     "shell.execute_reply": "2025-09-09T08:14:04.212357Z",
     "shell.execute_reply.started": "2025-09-09T08:12:47.150327Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.56.1)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.17.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.47.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch>=1.13.0->peft)\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.13.0->peft)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m64.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.4.0\n",
      "    Uninstalling triton-3.4.0:\n",
      "      Successfully uninstalled triton-3.4.0\n",
      "  Attempting uninstall: nvidia-cusparselt-cu12\n",
      "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
      "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
      "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
      "  Attempting uninstall: sympy\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
      "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 triton-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers peft datasets accelerate bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-09T08:14:04.214516Z",
     "iopub.status.busy": "2025-09-09T08:14:04.214226Z",
     "iopub.status.idle": "2025-09-09T08:14:04.726111Z",
     "shell.execute_reply": "2025-09-09T08:14:04.724990Z",
     "shell.execute_reply.started": "2025-09-09T08:14:04.214493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.874Z",
     "iopub.execute_input": "2025-09-09T08:14:04.727632Z",
     "iopub.status.busy": "2025-09-09T08:14:04.727264Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-09 08:14:14.301397: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757405654.335951     140 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757405654.346251     140 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c184bc61c7fb4f2e94b58c2d99b1c815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a84f88195f429abe90db19734b0e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/597k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a25da5897394c23a95c9080b49ae7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.15M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06370ecc3284663ba8d2a34ed3c98c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467f8acfe6264bc5865676a1160d12ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/169 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efd2f6d4bc14531bb2581d38696c613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e5aafc7e08438eb4c5a5cf58e9b694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0d500d24db487693e4f982db3cfa19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e78247908b4762b8310f8324ef797c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.59G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bc366a789e4a1aa020b83d84197447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95beb46ab9c4384aef9774cd1dffd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf90b1aee4e4cb2970a9a6a29a8fff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/133 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec432515b13b4346bf14e7637f90f314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72701bfa3e54629a716db244a44c50a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/444 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='1332' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  95/1332 01:06 < 14:46, 1.40 it/s, Epoch 0.21/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.619400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.900300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.773500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.873400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.851600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.385700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "model_name = \"Viet-Mistral/Vistral-7B-Chat\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",         \n",
    "    bnb_4bit_use_double_quant=True,     # Dùng double quantization để giảm lỗi\n",
    "    bnb_4bit_compute_dtype=torch.float16  \n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\", \n",
    "    use_cache=True\n",
    ")\n",
    "\n",
    "# Apply LoRA\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Load dữ liệu fine-tune từ file JSONL\n",
    "dataset = load_dataset(\"json\", data_files=\"finetune_data.jsonl\", split=\"train\")\n",
    "\n",
    "# Tokenize theo chat template\n",
    "def tokenize(example):\n",
    "    messages = example[\"messages\"]\n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", truncation=True, max_length=1024).squeeze()\n",
    "    return {\"input_ids\": input_ids, \"labels\": input_ids}\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=[\"messages\"])\n",
    "\n",
    "# Training config\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./vistral-law-finetuned\",\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    save_total_limit=1,\n",
    "    fp16=True,\n",
    "    learning_rate=2e-5,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# from peft import PeftModel\n",
    "# import torch\n",
    "\n",
    "# # Load tokenizer\n",
    "# model_name = \"Viet-Mistral/Vistral-7B-Chat\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Load base model (4bit nếu bạn dùng khi train)\n",
    "# from transformers import BitsAndBytesConfig\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\"\n",
    "# )\n",
    "\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=bnb_config,\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "\n",
    "# # Load LoRA weights từ thư mục fine-tune\n",
    "# model = PeftModel.from_pretrained(base_model, \"/kaggle/working/vistral-law-finetuned/checkpoint-666\")\n",
    "\n",
    "# # Prompt inference\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"Bạn là một trợ lý pháp luật tiếng Việt đáng tin cậy và chính xác.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Tôi có được phép tham gia vào hội đồng tư vấn tuyển chọn\"}\n",
    "# ]\n",
    "\n",
    "# # Apply chat template\n",
    "# input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# # Generate\n",
    "# with torch.no_grad():\n",
    "#     output = model.generate(\n",
    "#         input_ids=input_ids,\n",
    "#         max_new_tokens=512,\n",
    "#         do_sample=True,\n",
    "#         temperature=0.1,\n",
    "#         top_p=0.9,\n",
    "#         top_k=40\n",
    "#     )\n",
    "\n",
    "# response = tokenizer.decode(output[0][input_ids.shape[-1]:], skip_special_tokens=True)\n",
    "# print(\"Assistant:\", response.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd /kaggle/working/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd vistral-law-finetuned/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cd checkpoint-666/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from huggingface_hub import create_repo, upload_folder, login\n",
    "\n",
    "# # Đăng nhập Hugging Face\n",
    "# login(token=\"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\")\n",
    "\n",
    "\n",
    "\n",
    "# # Upload thư mục fine-tune\n",
    "# upload_folder(\n",
    "#     repo_id=\"kenvin1410/vistral-7b-law-lora\",\n",
    "#     folder_path=\"./\",\n",
    "#     path_in_repo=\".\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-09T08:18:30.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Lưu mô hình và tokenizer\n",
    "model.save_pretrained(\"./finetuned_model\")\n",
    "tokenizer.save_pretrained(\"./finetuned_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T06:23:31.936248Z",
     "iopub.status.busy": "2025-09-10T06:23:31.935574Z",
     "iopub.status.idle": "2025-09-10T06:23:31.942943Z",
     "shell.execute_reply": "2025-09-10T06:23:31.942244Z",
     "shell.execute_reply.started": "2025-09-10T06:23:31.936213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/vistral-law-finetuned\n"
     ]
    }
   ],
   "source": [
    "cd vistral-law-finetuned/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T06:26:28.237668Z",
     "iopub.status.busy": "2025-09-10T06:26:28.236976Z",
     "iopub.status.idle": "2025-09-10T06:26:28.379949Z",
     "shell.execute_reply": "2025-09-10T06:26:28.379154Z",
     "shell.execute_reply.started": "2025-09-10T06:26:28.237632Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mcheckpoint-500\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T06:26:29.994298Z",
     "iopub.status.busy": "2025-09-10T06:26:29.993739Z",
     "iopub.status.idle": "2025-09-10T06:26:29.999355Z",
     "shell.execute_reply": "2025-09-10T06:26:29.998680Z",
     "shell.execute_reply.started": "2025-09-10T06:26:29.994265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/vistral-law-finetuned/checkpoint-500\n"
     ]
    }
   ],
   "source": [
    "cd checkpoint-500/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-10T06:26:33.404483Z",
     "iopub.status.busy": "2025-09-10T06:26:33.404220Z",
     "iopub.status.idle": "2025-09-10T06:26:33.548816Z",
     "shell.execute_reply": "2025-09-10T06:26:33.547821Z",
     "shell.execute_reply.started": "2025-09-10T06:26:33.404466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adapter_config.json        README.md                tokenizer_config.json\n",
      "adapter_model.safetensors  rng_state.pth            tokenizer.json\n",
      "added_tokens.json          scaler.pt                tokenizer.model\n",
      "chat_template.jinja        scheduler.pt             trainer_state.json\n",
      "optimizer.pt               special_tokens_map.json  training_args.bin\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8192577,
     "sourceId": 12946029,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8233474,
     "sourceId": 13005527,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
